#!/usr/bin/env python3
# NOTE: This is a Python script (not JavaScript). Reviews/tooling should treat it as Python.

import os

# Disable debugger warnings
os.environ['PYDEVD_DISABLE_FILE_VALIDATION'] = '1'
os.environ['PYTHONDONTWRITEBYTECODE'] = '1'

import warnings
import logging
logging.basicConfig(level=logging.INFO, format="%(asctime)s %(levelname)s %(name)s: %(message)s")
logger = logging.getLogger("pipeline")

import gc
import json
import hashlib
import re
from pathlib import Path
from dataclasses import dataclass, asdict
from typing import Dict, List, Tuple, Optional, Union, Any
import tracemalloc
from urllib.error import URLError, HTTPError  # for precise NLTK download errors

import numpy as np
import pandas as pd
from scipy.sparse import hstack, csr_matrix, vstack, issparse
from scipy.stats import entropy
import unicodedata

from sklearn.model_selection import StratifiedKFold, GroupKFold
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.preprocessing import StandardScaler
from sklearn.decomposition import TruncatedSVD, NMF
from sklearn.linear_model import LogisticRegression, SGDClassifier
from sklearn.metrics import roc_auc_score, brier_score_loss
from sklearn.calibration import CalibratedClassifierCV
from sklearn.base import clone
from sklearn.exceptions import NotFittedError

import lightgbm as lgb
try:
    from catboost import CatBoostClassifier
    ADVANCED_MODELS = True
except ImportError:
    ADVANCED_MODELS = False
    missing = []
    try:
        import xgboost  # noqa: F401
    except Exception:
        missing.append("XGBoost")
    try:
        from catboost import CatBoostClassifier  # noqa: F401
    except Exception:
        missing.append("CatBoost")
    if not missing:
        missing.append("XGBoost/CatBoost")
    logger.info(f"Advanced models not available: {', '.join(missing)}")

try:
    from textblob import TextBlob
    from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer
    SENTIMENT_AVAILABLE = True
except ImportError:
    SENTIMENT_AVAILABLE = False

import nltk
NLTK_AVAILABLE = True
_nltk_error = getattr(nltk, "NLTKError", LookupError)

try:
    # NLTK resource probing & fallback (uses new/old tagger names)
    nltk.data.path.append('/kaggle/input/nltk-data/')

    def _has_tagger():
        try:
            nltk.data.find('taggers/averaged_perceptron_tagger_eng')
            return True
        except LookupError:
            try:
                nltk.data.find('taggers/averaged_perceptron_tagger')
                return True
            except LookupError:
                return False

    nltk.data.find('tokenizers/punkt')
    if not _has_tagger():
        raise LookupError("POS tagger not found")
except LookupError:
    if not os.path.exists('/kaggle'):
        nltk.download('punkt', quiet=True)
        try:
            nltk.download('averaged_perceptron_tagger_eng', quiet=True)
        except (URLError, HTTPError, OSError):
            nltk.download('averaged_perceptron_tagger', quiet=True)
    else:
        NLTK_AVAILABLE = False
except (LookupError, OSError) as exc:
    NLTK_AVAILABLE = False
    warnings.warn(f"NLTK resources unavailable: {exc}")

try:
    import optuna
    from optuna.pruners import MedianPruner
    OPTUNA_AVAILABLE = True
except ImportError:
    OPTUNA_AVAILABLE = False

try:
    import torch
    from transformers import AutoTokenizer, AutoModel, AutoModelForSequenceClassification
    from transformers import get_linear_schedule_with_warmup
    from torch.optim import AdamW
    TRANSFORMERS_AVAILABLE = True
except ImportError:
    TRANSFORMERS_AVAILABLE = False
    logger.info("Transformers not available")

def set_all_seeds(seed=42):
    os.environ['PYTHONHASHSEED'] = str(seed)
    np.random.seed(seed)
    if TRANSFORMERS_AVAILABLE:
        torch.manual_seed(seed)
        torch.cuda.manual_seed_all(seed)

# For library use, call set_all_seeds() in main(); avoid side effects on import.

@dataclass
class TrainSpec:
    train_path: str = "/kaggle/input/jigsaw-agile-community-rules/train.csv"
    test_path: str = "/kaggle/input/jigsaw-agile-community-rules/test.csv"
    model_path: str = "/kaggle/working/models"
    
    random_state: int = 42
    cv_folds: int = 5
    early_stopping_rounds: int = 50
    
    max_tfidf_features: int = 30000
    max_char_features: int = 20000
    svd_dim: int = 1024
    use_sentiment: bool = SENTIMENT_AVAILABLE
    use_pos_features: bool = True
    topic_components: int = 20
    
    use_transformer: bool = TRANSFORMERS_AVAILABLE
    transformer_model: str = "distilbert-base-uncased"
    use_stacking: bool = True
    use_hierarchical: bool = True
    use_borderline_gate: bool = True
    # Router/gate and curriculum knobs
    hierarchical_top_k: int = 3
    hier_expert_min_samples: int = 50
    borderline_low: float = 0.4
    borderline_high: float = 0.6
    entropy_threshold: float = 0.5
    transformer_epochs: int = 3
    transformer_max_length: int = 512
    transformer_patience: int = 2
    transformer_val_fraction: float = 0.1
    curriculum_stages: Tuple[Tuple[float, int], ...] = ((0.33, 5), (0.67, 3), (1.0, 2))
    pos_max_chars: int = 500
    pos_tags: Tuple[str, ...] = ("NN", "VB", "JJ", "RB")

    use_curriculum: bool = True
    use_pseudo_labeling: bool = False
    use_adversarial_validation: bool = True
    use_augmentation: bool = True
    augmentation_ratio: float = 0.2
    augmentation_max: int = 200
    augmentation_noise_std: float = 0.01  # documentable knob
    
    calibration_mode: str = "sigmoid"
    min_samples_isotonic: int = 300
    
    use_onnx: bool = False
    use_conformal: bool = True
    track_drift: bool = True
    
    optimize_hyperparams: bool = OPTUNA_AVAILABLE
    optuna_trials: int = 60
    optuna_patience: int = 5
    
    memory_limit_mb: int = 30000
    n_jobs: int = -1
    batch_size: int = 32
    # Adversarial validation sampling caps
    adv_val_max_train: int = 5000
    adv_val_max_all: int = 10000
    # CatBoost feature toggle
    catboost_use_svd: bool = False

class CrossValidator:
    def __init__(self, spec: TrainSpec):
        self.spec = spec
        self.main_splitter = None
        self.group_splitter = None
        
    def setup(self, y: np.ndarray, groups: Optional[np.ndarray] = None):
        self.main_splitter = StratifiedKFold(
            n_splits=self.spec.cv_folds,
            shuffle=True,
            random_state=self.spec.random_state
        )
        
        if groups is not None and len(np.unique(groups)) >= 2:
            n_splits = min(self.spec.cv_folds, len(np.unique(groups)))
            try:
                self.group_splitter = GroupKFold(n_splits=n_splits)
                logger.info(f"Using GroupKFold with {len(np.unique(groups))} groups and {n_splits} splits")
            except ValueError as e:
                logger.warning(f"GroupKFold unavailable ({e}); falling back to StratifiedKFold")
                self.group_splitter = None
        
    def split(self, X, y, groups=None):
        if self.group_splitter and groups is not None:
            return self.group_splitter.split(X, y, groups)
        else:
            return self.main_splitter.split(X, y)
    
    def get_calibration_method(self, n_samples: int) -> str:
        if n_samples >= self.spec.min_samples_isotonic:
            return "isotonic"
        return self.spec.calibration_mode

class RobustFeatureEngineer:
    """Builds TF-IDF + char n-grams, SVD projection, topic NMF, and meta/sentiment/POS features."""
    def __init__(self, spec: TrainSpec):
        self.spec = spec
        self.word_vectorizer = None
        self.char_vectorizer = None
        self.topic_vectorizer = None
        self.topic_model = None
        self.svd = None
        self.scaler = None
        self.pos_cache = {}
        self.sentiment_analyzer = None
        
    def fit(self, texts: pd.Series, y: np.ndarray = None):
        logger.info("Fitting feature transformers…")
        
        texts_clean = texts.apply(self._clean_text)
        
        self.word_vectorizer = TfidfVectorizer(
            ngram_range=(1, 2),
            max_features=self.spec.max_tfidf_features,
            min_df=2,
            max_df=0.95,
            sublinear_tf=True,
            dtype=np.float32
        )
        self.word_vectorizer.fit(texts_clean)
        
        self.char_vectorizer = TfidfVectorizer(
            analyzer='char',
            ngram_range=(3, 6),
            max_features=self.spec.max_char_features,
            min_df=5,
            max_df=0.95,
            sublinear_tf=True,
            dtype=np.float32
        )
        self.char_vectorizer.fit(texts_clean)
        
        self.topic_vectorizer = TfidfVectorizer(
            max_features=5000,
            min_df=2,
            max_df=0.95
        )
        topic_matrix = self.topic_vectorizer.fit_transform(texts_clean)
        
        self.topic_model = NMF(
            n_components=self.spec.topic_components,
            random_state=self.spec.random_state,
            init='nndsvda'
        )
        self.topic_model.fit(topic_matrix)

        # Fit SVD & scaler here to avoid leakage (moved from transform)
        word_features = self.word_vectorizer.transform(texts_clean)
        char_features = self.char_vectorizer.transform(texts_clean)
        tfidf_combined = hstack([word_features, char_features], format='csr')
        self.svd = TruncatedSVD(
            n_components=min(self.spec.svd_dim, tfidf_combined.shape[1] - 1),
            random_state=self.spec.random_state
        )
        tfidf_reduced = self.svd.fit_transform(tfidf_combined)
        self.scaler = StandardScaler(with_mean=True)
        self.scaler.fit(tfidf_reduced)

        if self.spec.use_sentiment and SENTIMENT_AVAILABLE:
            self.sentiment_analyzer = SentimentIntensityAnalyzer()

        return self
    
    def transform(self, texts: pd.Series) -> Dict[str, np.ndarray]:
        if self.word_vectorizer is None:
            raise ValueError("Must fit before transform")
        
        texts_clean = texts.apply(self._clean_text)
        
        features = {}
        
        word_features = self.word_vectorizer.transform(texts_clean)
        char_features = self.char_vectorizer.transform(texts_clean)
        
        tfidf_combined = hstack([word_features, char_features], format='csr')
        # Transform only (fit happened in fit())
        tfidf_reduced = self.svd.transform(tfidf_combined)
        tfidf_reduced = self.scaler.transform(tfidf_reduced)

        features['sparse_reduced'] = csr_matrix(tfidf_reduced)
        features['svd_reduced'] = features['sparse_reduced']
        
        topic_matrix = self.topic_vectorizer.transform(texts_clean)
        topic_features = self.topic_model.transform(topic_matrix)
        features['topic'] = topic_features
        
        meta_features = self._extract_meta_features(texts_clean)
        features['meta'] = meta_features
        
        if self.spec.use_sentiment:
            sentiment_features = self._extract_sentiment_features(texts_clean)
            features['sentiment'] = sentiment_features
        
        if self.spec.use_pos_features:
            pos_features = self._extract_pos_features(texts_clean)
            features['pos'] = pos_features
        
        return features
    
    def _clean_text(self, text: str) -> str:
        text = str(text)
        
        text = unicodedata.normalize('NFKD', text)
        
        text = text.encode('ascii', 'ignore').decode('ascii')
        
        text = re.sub(r'http\S+|www.\S+', '[URL]', text)
        text = re.sub(r'\S+@\S+', '[EMAIL]', text)
        text = re.sub(r'@\w+', '[USER]', text)
        
        text = re.sub(r'<[^>]+>', '', text)
        
        return text
    
    def _extract_meta_features(self, texts: pd.Series) -> np.ndarray:
        features = []
        
        for text in texts:
            text = str(text)
            
            n_chars = len(text)
            n_words = len(text.split())
            n_unique = len(set(text.lower().split()))
            
            n_caps = sum(1 for c in text if c.isupper())
            n_punct = sum(1 for c in text if c in '!?.,:;')
            n_digits = sum(1 for c in text if c.isdigit())
            
            elongations = len(re.findall(r'(.)\1{2,}', text))
            leetspeak = sum(1 for pair in [('a','@'),('e','3'),('i','!'),('l','1'),('s','$')] 
                          if pair[1] in text)
            
            features.append([
                np.log1p(n_chars),
                np.log1p(n_words),
                np.log1p(n_unique),
                n_unique / (n_words + 1),
                n_caps / (n_chars + 1),
                n_punct / (n_chars + 1),
                n_digits / (n_chars + 1),
                np.log1p(elongations),
                np.log1p(leetspeak)
            ])
        
        return np.array(features, dtype=np.float32)
    
    def _extract_sentiment_features(self, texts: pd.Series) -> np.ndarray:
        features = []
        
        for text in texts:
            text_str = str(text)
            
            try:
                blob = TextBlob(text_str)
                polarity = blob.sentiment.polarity
                subjectivity = blob.sentiment.subjectivity
            except (ValueError, TypeError, AttributeError) as exc:
                import warnings as _warn
                _warn.warn(f"TextBlob sentiment failed: {exc}")
                polarity, subjectivity = 0, 0
            
            if self.sentiment_analyzer:
                scores = self.sentiment_analyzer.polarity_scores(text_str)
                compound = scores['compound']
                pos = scores['pos']
                neg = scores['neg']
                neu = scores['neu']
            else:
                compound, pos, neg, neu = 0, 0, 0, 0
            
            features.append([polarity, subjectivity, compound, pos, neg, neu])
        
        return np.array(features, dtype=np.float32)
    
    def _extract_pos_features(self, texts: pd.Series) -> np.ndarray:
        features = []
        
        for text in texts:
            text_hash = hashlib.md5(str(text).encode()).hexdigest()
            
            if text_hash not in self.pos_cache:
                if NLTK_AVAILABLE:
                    try:
                        import nltk
                        # Truncate for speed; configurable via TrainSpec.pos_max_chars
                        tokens = nltk.word_tokenize(str(text)[:self.spec.pos_max_chars])
                        pos_tags = nltk.pos_tag(tokens)
                        
                        pos_counts = {}
                        for _, tag in pos_tags:
                            category = tag[:2]
                            pos_counts[category] = pos_counts.get(category, 0) + 1

                        total = len(pos_tags) + 1
                        buckets = [pos_counts.get(tag, 0) / total for tag in self.spec.pos_tags]
                        feature_vec = buckets + [0.0]
                    except (LookupError, _nltk_error, OSError, ValueError, TypeError) as e:
                        logger.exception(
                            "POS feature extraction failed; using missing-indicator fallback: %s",
                            e,
                        )
                        feature_vec = [0.0] * len(self.spec.pos_tags) + [1.0]
                else:
                    feature_vec = [0.0] * len(self.spec.pos_tags) + [1.0]
                
                self.pos_cache[text_hash] = feature_vec
            
            features.append(self.pos_cache[text_hash])
        
        return np.array(features, dtype=np.float32)

class TransformerBackbone:
    """Optional transformer backbone for fine-tuning or embedding extraction."""
    def __init__(self, spec: TrainSpec, mode='fine_tune'):
        self.spec = spec
        self.mode = mode
        self.model = None
        self.tokenizer = None
        if TRANSFORMERS_AVAILABLE:
            self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
        else:
            self.device = None
        self.ready = False

    def setup(self, n_labels=2, multi_task=False):
        if not TRANSFORMERS_AVAILABLE:
            return None

        try:
            self.tokenizer = AutoTokenizer.from_pretrained(self.spec.transformer_model)

            if self.mode == 'fine_tune':
                self.model = AutoModelForSequenceClassification.from_pretrained(
                    self.spec.transformer_model,
                    num_labels=n_labels
                )
            else:
                self.model = AutoModel.from_pretrained(self.spec.transformer_model)
        except (OSError, EnvironmentError) as exc:
            logger.warning(
                "Transformer backbone unavailable (%s); continuing without transformer features.",
                exc
            )
            self.model = None
            self.tokenizer = None
            self.ready = False
            return None

        self.model.to(self.device)
        self.ready = True
        return self

    def is_ready(self):
        return self.ready and self.model is not None and self.tokenizer is not None

    def fine_tune(self, texts, labels, val_texts=None, val_labels=None):
        if self.mode != 'fine_tune' or not TRANSFORMERS_AVAILABLE:
            return

        from torch.utils.data import DataLoader, TensorDataset
        from sklearn.model_selection import train_test_split

        labels_array = np.array(labels)
        texts_array = texts.to_numpy() if hasattr(texts, "to_numpy") else np.array(list(texts))

        if val_texts is None or val_labels is None:
            if len(labels_array) > 1 and len(np.unique(labels_array)) > 1:
                idx = np.arange(len(labels_array))
                tr_idx, va_idx = train_test_split(
                    idx,
                    test_size=self.spec.transformer_val_fraction,
                    random_state=self.spec.random_state,
                    stratify=labels_array,
                )
                train_texts = texts_array[tr_idx]
                train_labels = labels_array[tr_idx]
                v_texts = texts_array[va_idx]
                v_labels = labels_array[va_idx]
            else:
                train_texts = texts_array
                train_labels = labels_array
                v_texts = None
                v_labels = None
        else:
            train_texts = texts_array
            train_labels = labels_array
            v_texts = val_texts.to_numpy() if hasattr(val_texts, "to_numpy") else np.array(list(val_texts))
            v_labels = np.array(val_labels)

        max_len = self.spec.transformer_max_length
        train_encodings = self.tokenizer(
            train_texts.tolist(),
            truncation=True,
            padding=True,
            max_length=max_len,
            return_tensors='pt'
        )

        train_dataset = TensorDataset(
            train_encodings['input_ids'],
            train_encodings['attention_mask'],
            torch.tensor(train_labels)
        )

        train_loader = DataLoader(
            train_dataset,
            batch_size=self.spec.batch_size,
            shuffle=True
        )

        optimizer = AdamW(self.model.parameters(), lr=2e-5)
        total_steps = len(train_loader) * self.spec.transformer_epochs
        scheduler = get_linear_schedule_with_warmup(
            optimizer,
            num_warmup_steps=int(0.1 * total_steps),
            num_training_steps=total_steps
        )

        best_state = None
        best_val = float("inf")
        bad = 0
        self.model.train()
        for epoch in range(self.spec.transformer_epochs):
            for batch in train_loader:
                batch = tuple(t.to(self.device) for t in batch)
                inputs = {
                    'input_ids': batch[0],
                    'attention_mask': batch[1],
                    'labels': batch[2]
                }
                
                optimizer.zero_grad()
                outputs = self.model(**inputs)
                loss = outputs.loss
                loss.backward()
                optimizer.step()
                scheduler.step()

            if v_texts is not None and len(v_texts) > 0:
                self.model.eval()
                with torch.no_grad():
                    v_enc = self.tokenizer(
                        v_texts.tolist(),
                        truncation=True,
                        padding=True,
                        max_length=max_len,
                        return_tensors='pt'
                    ).to(self.device)
                    v_outputs = self.model(
                        **v_enc,
                        labels=torch.tensor(v_labels).to(self.device)
                    )
                    v_loss = float(v_outputs.loss.detach().cpu().item())
                self.model.train()
                logger.info(f"Transformer epoch {epoch + 1}: val_loss={v_loss:.4f}")
                if v_loss + 1e-6 < best_val:
                    best_val = v_loss
                    bad = 0
                    best_state = {k: v.detach().cpu().clone() for k, v in self.model.state_dict().items()}
                else:
                    bad += 1
                    if bad >= self.spec.transformer_patience:
                        logger.info("Early stopping transformer fine-tune.")
                        break

        if best_state is not None:
            self.model.load_state_dict(best_state)
    
    def get_embeddings(self, texts):
        if not TRANSFORMERS_AVAILABLE or not self.is_ready():
            return None

        self.model.eval()
        embeddings = []
        
        with torch.no_grad():
            for i in range(0, len(texts), self.spec.batch_size):
                batch_texts = texts[i:i+self.spec.batch_size].tolist()
                
                encodings = self.tokenizer(
                    batch_texts,
                    truncation=True,
                    padding=True,
                    max_length=self.spec.transformer_max_length,
                    return_tensors='pt'
                ).to(self.device)
                
                outputs = self.model(**encodings)
                
                if hasattr(outputs, 'last_hidden_state'):
                    hidden = outputs.last_hidden_state
                else:
                    hidden = outputs[0]
                
                pooled = hidden.mean(dim=1).cpu().numpy()
                embeddings.append(pooled)
        
        return np.vstack(embeddings)

class StackingEnsemble:
    def __init__(self, spec: TrainSpec):
        self.spec = spec
        self.base_models = {}
        self.meta_model = None
        self.oof_predictions = None
        self.calibrators = {}
        
    def setup_models(self, X_shape):
        self.base_models['logreg'] = LogisticRegression(
            max_iter=2000,
            C=1.0,
            solver='liblinear',
            class_weight='balanced',
            random_state=self.spec.random_state
        )
        
        self.base_models['sgd'] = SGDClassifier(
            loss='log_loss',
            penalty='elasticnet',
            l1_ratio=0.15,
            class_weight='balanced',
            random_state=self.spec.random_state
        )
        
        self.base_models['lgbm_sparse'] = lgb.LGBMClassifier(
            n_estimators=1000,
            learning_rate=0.05,
            num_leaves=31,
            min_child_samples=20,
            subsample=0.8,
            colsample_bytree=0.8,
            random_state=self.spec.random_state,
            verbosity=-1
        )
        
        if ADVANCED_MODELS:
            self.base_models['catboost'] = CatBoostClassifier(
                iterations=500,
                learning_rate=0.05,
                depth=6,
                random_seed=self.spec.random_state,
                verbose=False
            )
        self.model_features = {
            'logreg': ['sparse_reduced'],
            'sgd': ['sparse_reduced'],
            'lgbm_sparse': ['sparse_reduced'],
        }
        if ADVANCED_MODELS:
            self.model_features['catboost'] = (
                ['sparse_reduced', 'meta', 'topic'] if self.spec.catboost_use_svd else ['meta', 'topic']
            )

    def _assemble_features(self, X_dict, feat_keys):
        """Safely stack model features, preserving sparsity if needed."""
        arrays = [X_dict[key] for key in feat_keys]
        if len(arrays) == 1:
            return arrays[0]
        any_sparse = any(issparse(arr) or hasattr(arr, "tocsr") for arr in arrays)
        if any_sparse:
            arrays = [arr if issparse(arr) else csr_matrix(arr) for arr in arrays]
            return hstack(arrays, format='csr')
        return np.hstack(arrays)

    @staticmethod
    def _fit_with_sw(model, X, y, sw):
        """Fit with sample_weight if supported; avoid masking other TypeErrors."""
        from inspect import signature
        sig = signature(model.fit)
        if 'sample_weight' in sig.parameters and sw is not None:
            return model.fit(X, y, sample_weight=sw)
        return model.fit(X, y)

    def fit(self, X_dict, y, cv_splitter, groups=None, sample_weight=None):
        n_samples = len(y)
        n_models = len(self.base_models)

        self.oof_predictions = np.zeros((n_samples, n_models))

        for fold_idx, (train_idx, val_idx) in enumerate(cv_splitter.split(X_dict['sparse_reduced'], y, groups)):
            logger.info(f"Generating OOF for fold {fold_idx + 1}")

            for model_idx, (name, model) in enumerate(self.base_models.items()):
                feat_keys = self.model_features.get(name, ['sparse_reduced'])
                X_full = self._assemble_features(X_dict, feat_keys)
                X_train = X_full[train_idx]
                X_val = X_full[val_idx]

                model_clone = clone(model)
                sw = sample_weight[train_idx] if sample_weight is not None else None
                if ADVANCED_MODELS and name == 'catboost' and issparse(X_train):
                    X_train = X_train.toarray()
                    X_val = X_val.toarray()
                self._fit_with_sw(model_clone, X_train, y[train_idx], sw)
                pred = model_clone.predict_proba(X_val)[:, 1]

                self.oof_predictions[val_idx, model_idx] = pred

        self.meta_model = LogisticRegression(max_iter=1000, solver='lbfgs')
        meta_fit_kwargs = {}
        if sample_weight is not None:
            meta_fit_kwargs['sample_weight'] = sample_weight
        self.meta_model.fit(self.oof_predictions, y, **meta_fit_kwargs)

        logger.info("Refitting base models and calibrating…")
        for name, model in self.base_models.items():
            feat_keys = self.model_features.get(name, ['sparse_reduced'])
            X_full = self._assemble_features(X_dict, feat_keys)

            sw_full = sample_weight if sample_weight is not None else None
            if ADVANCED_MODELS and name == 'catboost' and issparse(X_full):
                X_full = X_full.toarray()

            self._fit_with_sw(model, X_full, y, sw_full)
            from sklearn.model_selection import StratifiedKFold
            skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=self.spec.random_state)
            tr_idx, cal_idx = next(skf.split(X_full, y))
            X_tr, y_tr = X_full[tr_idx], y[tr_idx]
            X_cal, y_cal = X_full[cal_idx], y[cal_idx]
            sw_tr = sw_full[tr_idx] if sw_full is not None else None
            sw_cal = sw_full[cal_idx] if sw_full is not None else None

            if ADVANCED_MODELS and name == 'catboost':
                if issparse(X_tr):
                    X_tr = X_tr.toarray()
                if issparse(X_cal):
                    X_cal = X_cal.toarray()

            model_for_cal = clone(model)
            self._fit_with_sw(model_for_cal, X_tr, y_tr, sw_tr)
            method = cv_splitter.get_calibration_method(len(y))
            self.calibrators[name] = CalibratedClassifierCV(base_estimator=model_for_cal, method=method, cv='prefit')
            if sw_cal is not None:
                self.calibrators[name].fit(X_cal, y_cal, sample_weight=sw_cal)
            else:
                self.calibrators[name].fit(X_cal, y_cal)

        return self

    def predict(self, X_dict):
        predictions = []

        for name, model in self.base_models.items():
            feat_keys = self.model_features.get(name, ['sparse_reduced'])
            X = self._assemble_features(X_dict, feat_keys)

            if ADVANCED_MODELS and name == 'catboost' and issparse(X):
                X = X.toarray()
            pred = self.calibrators[name].predict_proba(X)[:, 1]
            predictions.append(pred)

        stacked = np.column_stack(predictions)
        final_pred = self.meta_model.predict_proba(stacked)[:, 1]

        return np.clip(final_pred, 0.0, 1.0)

class HierarchicalRouter:
    def __init__(self, spec: TrainSpec):
        self.spec = spec
        self.rule_classifier = None
        self.violation_experts = {}
        self.rule_classes_ = None
        
    def fit(self, X_dict, y, rules):
        self.rule_classifier = lgb.LGBMClassifier(
            n_estimators=500,
            random_state=self.spec.random_state,
            verbosity=-1
        )
        
        X_combined = hstack([
            X_dict['sparse_reduced'],
            csr_matrix(X_dict['meta'])
        ], format='csr')
        
        self.rule_classifier.fit(X_combined, rules)
        self.rule_classes_ = self.rule_classifier.classes_  # set once; no need to re-check later
        
        unique_rules = np.unique(rules)
        for rule in unique_rules:
            mask = rules == rule
            if mask.sum() >= self.spec.hier_expert_min_samples:
                X_rule = X_combined[mask]
                y_rule = y[mask]
                
                expert = CalibratedClassifierCV(
                    lgb.LGBMClassifier(
                        n_estimators=300,
                        random_state=self.spec.random_state,
                        verbosity=-1
                    ),
                    method='sigmoid',
                    cv=3
                )
                expert.fit(X_rule, y_rule)
                self.violation_experts[rule] = expert
        
        return self
    
    def predict(self, X_dict, known_rules=None):
        X_combined = hstack([
            X_dict['sparse_reduced'],
            csr_matrix(X_dict['meta'])
        ], format='csr')
        
        n_samples = X_combined.shape[0]
        routed_scores = np.zeros(n_samples)
        mixture_scores = np.zeros(n_samples)
        
        if known_rules is not None:
            for i, rule in enumerate(known_rules):
                if rule in self.violation_experts:
                    routed_scores[i] = self.violation_experts[rule].predict_proba(
                        X_combined[i:i+1]
                    )[0, 1]
                else:
                    routed_scores[i] = 0.5
        
        rule_probs = self.rule_classifier.predict_proba(X_combined)

        if self.rule_classes_ is None:
            raise NotFittedError(
                "HierarchicalRouter is not fitted yet. Call fit() before predict()."
            )
        classes = self.rule_classes_
        top_k = getattr(self.spec, "hierarchical_top_k", 3)

        for i in range(n_samples):
            top_rules = np.argsort(rule_probs[i])[-top_k:]
            
            weighted_score = 0
            weight_sum = 0
            
            for rule_idx in top_rules:
                rule = classes[rule_idx]
                if rule in self.violation_experts:
                    prob = rule_probs[i, rule_idx]
                    violation_prob = self.violation_experts[rule].predict_proba(
                        X_combined[i:i+1]
                    )[0, 1]
                    weighted_score += prob * violation_prob
                    weight_sum += prob
            
            mixture_scores[i] = weighted_score / (weight_sum + 1e-10)
        
        return routed_scores, mixture_scores

class BorderlineGate:
    def __init__(self, spec: TrainSpec, entropy_threshold=0.5):
        self.spec = spec
        self.entropy_threshold = getattr(self.spec, "entropy_threshold", entropy_threshold)
        self.fast_model = None
        
    def fit(self, X_dict, y, sample_weight=None):
        self.fast_model = LogisticRegression(
            max_iter=1000,
            solver='liblinear',
            class_weight='balanced',
            random_state=self.spec.random_state
        )

        if sample_weight is not None:
            self.fast_model.fit(X_dict['sparse_reduced'], y, sample_weight=sample_weight)
        else:
            self.fast_model.fit(X_dict['sparse_reduced'], y)
        return self
    
    def should_route_to_expensive(self, X_dict, base_predictions):
        fast_prob = self.fast_model.predict_proba(X_dict['sparse_reduced'])[:, 1]
        
        pred_entropy = entropy(np.column_stack([
            base_predictions,
            1 - base_predictions
        ]), axis=1)

        low = getattr(self.spec, "borderline_low", 0.4)
        high = getattr(self.spec, "borderline_high", 0.6)
        borderline_mask = ((fast_prob > low) & (fast_prob < high)) | (
            pred_entropy > self.entropy_threshold
        )
        
        return borderline_mask

class ProductionPipeline:
    def __init__(self, spec: TrainSpec):
        self.spec = spec
        self.cv = CrossValidator(spec)
        self.feature_engineer = RobustFeatureEngineer(spec)
        self.stacker = None
        self.hierarchical = None
        self.gate = None
        self.transformer = None
        self.adversarial_weights = None
        self.drift_monitor = {}
        self.model_bundle = {}
        
    def run_adversarial_validation(self, X_train_dict, X_test_dict):
        logger.info("Adversarial Validation:")

        adv_scores = {}

        for feat_name in ['sparse_reduced', 'meta', 'topic']:
            if feat_name not in X_train_dict:
                continue

            X_train = X_train_dict[feat_name]
            X_test = X_test_dict[feat_name]

            n_train = min(self.spec.adv_val_max_train, X_train.shape[0])
            n_test = min(self.spec.adv_val_max_train, X_test.shape[0])

            X_train_sample = X_train[:n_train]
            X_test_sample = X_test[:n_test]

            from scipy.sparse import vstack as sp_vstack
            X_combined = sp_vstack([X_train_sample, X_test_sample]) if issparse(X_train_sample) else np.vstack([X_train_sample, X_test_sample])
            y_combined = np.concatenate([
                np.zeros(n_train),
                np.ones(n_test)
            ])
            
            clf = lgb.LGBMClassifier(
                n_estimators=100,
                random_state=self.spec.random_state,
                verbosity=-1
            )

            from sklearn.model_selection import cross_val_score
            scores = cross_val_score(clf, X_combined, y_combined, cv=3, scoring='roc_auc')
            adv_scores[feat_name] = scores.mean()

            logger.info(f"  {feat_name}: AUC = {scores.mean():.3f}")

        if not adv_scores:
            self.adversarial_weights = None
            return

        max_score = max(adv_scores.values())
        if max_score > 0.7:
            logger.info(f"  Distribution shift detected (max AUC = {max_score:.3f})")

            X_train_all = self._combine_features(X_train_dict)
            X_test_all = self._combine_features(X_test_dict)

            n_train = min(self.spec.adv_val_max_all, X_train_all.shape[0])
            n_test = min(self.spec.adv_val_max_all, X_test_all.shape[0])

            X_combined = vstack([X_train_all[:n_train], X_test_all[:n_test]])
            y_combined = np.concatenate([np.zeros(n_train), np.ones(n_test)])

            clf.fit(X_combined, y_combined)

            train_probs = clf.predict_proba(X_train_all)[:, 1]
            self.adversarial_weights = (1 - train_probs) / (train_probs + 1e-10)
            self.adversarial_weights = np.clip(self.adversarial_weights, 0.1, 10)

            logger.info(f"  Applied importance weights: mean={self.adversarial_weights.mean():.2f}")
        else:
            self.adversarial_weights = None
    
    def _combine_features(self, X_dict):
        features = []

        if 'sparse_reduced' in X_dict:
            features.append(X_dict['sparse_reduced'])

        for key in ['meta', 'topic', 'sentiment', 'pos']:
            if key in X_dict:
                arr = X_dict[key]
                features.append(arr if issparse(arr) else csr_matrix(arr))

        return hstack(features, format='csr')
    
    def train_with_curriculum(self, X_dict, y):
        if not self.spec.use_curriculum:
            return None
        
        logger.info("Curriculum Learning:")
        
        simple_model = LogisticRegression(
            max_iter=100,
            solver='liblinear',
            random_state=self.spec.random_state
        )
        simple_model.fit(X_dict['sparse_reduced'], y)
        
        probas = simple_model.predict_proba(X_dict['sparse_reduced'])[:, 1]
        difficulties = np.abs(probas - 0.5)
        
        sorted_idx = np.argsort(difficulties)
        
        if self.spec.use_transformer and self.transformer:
            for fraction, epochs in self.spec.curriculum_stages:
                end_idx = int(fraction * len(sorted_idx))
                stage_idx = sorted_idx[:end_idx]

                logger.info(f"  Stage: {fraction:.0%} of data ({len(stage_idx)} samples)")
                # TODO: integrate stage-specific fine-tuning once transformer training is enabled
    
    def fit(self, train_df: pd.DataFrame, test_df: pd.DataFrame = None):
        logger.info("=" * 60)
        logger.info("PRODUCTION PIPELINE")
        logger.info("=" * 60)

        tracemalloc.start()

        y_train = train_df['rule_violation'].values
        if 'subreddit' in train_df.columns:
            groups = train_df['subreddit'].values
        elif 'rule' in train_df.columns:
            groups = train_df['rule'].values
        else:
            groups = None
        rules = train_df['rule'].values if 'rule' in train_df.columns else None

        self.cv.setup(y_train, groups)

        logger.info("Feature Engineering…")
        train_text = self._compose_texts(train_df)
        self.feature_engineer.fit(train_text, y_train)

        X_train_dict = self.feature_engineer.transform(train_text)

        if test_df is not None:
            test_text = self._compose_texts(test_df)
            X_test_dict = self.feature_engineer.transform(test_text)

            if self.spec.use_adversarial_validation:
                self.run_adversarial_validation(X_train_dict, X_test_dict)

        if self.spec.use_augmentation:
            X_train_dict, y_train, groups, rules = self._augment_data(X_train_dict, y_train, train_df, groups, rules)

        if self.spec.use_transformer:
            logger.info("Setting up Transformer backbone…")
            self.transformer = TransformerBackbone(self.spec, mode='embed_only')
            self.transformer.setup()

            if not self.transformer.is_ready():
                logger.info("Transformer backbone disabled; proceeding without transformer features.")
                self.transformer = None
            else:
                embeddings = self.transformer.get_embeddings(train_text)
                if embeddings is not None:
                    X_train_dict['transformer'] = embeddings

        if self.spec.use_curriculum:
            self.train_with_curriculum(X_train_dict, y_train)

        if self.spec.use_stacking:
            logger.info("Training Stacking Ensemble…")
            self.stacker = StackingEnsemble(self.spec)
            self.stacker.setup_models(X_train_dict['sparse_reduced'].shape)
            self.stacker.fit(
                X_train_dict,
                y_train,
                self.cv,
                groups,
                sample_weight=self.adversarial_weights
            )

            self.model_bundle['oof_predictions'] = self.stacker.oof_predictions

        if self.spec.use_hierarchical and rules is not None:
            logger.info("Training Hierarchical Router…")
            self.hierarchical = HierarchicalRouter(self.spec)
            self.hierarchical.fit(X_train_dict, y_train, rules)

        if self.spec.use_borderline_gate:
            logger.info("Training Borderline Gate…")
            self.gate = BorderlineGate(self.spec)
            self.gate.fit(X_train_dict, y_train, sample_weight=self.adversarial_weights)

        self._setup_drift_monitor(X_train_dict, y_train)

        self._run_error_analysis(X_train_dict, y_train, groups)

        self._save_model_bundle()

        current, peak = tracemalloc.get_traced_memory()
        tracemalloc.stop()
        logger.info(f"Memory: Current={current/1024/1024:.1f}MB, Peak={peak/1024/1024:.1f}MB")

        return self
    
    def predict(self, test_df: pd.DataFrame, return_all_scores=False):
        test_text = self._compose_texts(test_df)
        X_test_dict = self.feature_engineer.transform(test_text)
        
        if self.transformer and self.transformer.is_ready():
            embeddings = self.transformer.get_embeddings(test_text)
            if embeddings is not None:
                X_test_dict['transformer'] = embeddings
        
        results = {}
        
        if self.stacker:
            stacked_pred = self.stacker.predict(X_test_dict)
            results['stacked'] = stacked_pred
        
        if self.hierarchical:
            known_rules = test_df.get('rule', None)
            routed, mixture = self.hierarchical.predict(X_test_dict, known_rules)
            results['routed'] = routed
            results['mixture'] = mixture
        
        if self.gate and self.stacker:
            base_preds_list = []
            for name, _ in self.stacker.base_models.items():
                feat_keys = self.stacker.model_features.get(name, ['sparse_reduced'])
                X = self.stacker._assemble_features(X_test_dict, feat_keys)
                if ADVANCED_MODELS and name == 'catboost' and issparse(X):
                    X = X.toarray()
                pred = self.stacker.calibrators[name].predict_proba(X)[:, 1]
                base_preds_list.append(pred)

            base_preds = np.column_stack(base_preds_list).mean(axis=1)
            borderline_mask = self.gate.should_route_to_expensive(X_test_dict, base_preds)
            results['borderline_mask'] = borderline_mask
        
        if 'stacked' in results:
            final_pred = results['stacked']
        elif 'mixture' in results:
            final_pred = results['mixture']
        else:
            final_pred = np.ones(len(test_df)) * 0.5
        
        if return_all_scores:
            return final_pred, results
        return final_pred
    
    def _compose_texts(self, df):
        """Vectorized text composer from columns; avoids Python-level loops."""
        cols = df.columns
        empty = pd.Series([''] * len(df))
        body = df['body'].where(df['body'].notna(), '').astype(str) if 'body' in cols else empty
        rule = df['rule'].where(df['rule'].notna(), '').astype(str) if 'rule' in cols else empty
        subr = df['subreddit'].where(df['subreddit'].notna(), '').astype(str) if 'subreddit' in cols else empty
        base = (
            ((('[CONTENT] ' + body).where(body != '', '') + ' ').str.strip() + ' ' +
             (('[RULE] ' + rule).where(rule != '', '') + ' ').str.strip() + ' ' +
             (('[COMMUNITY] r/' + subr).where(subr != '', '')).str.strip()).str.strip()
        )
        pos_cols = [c for c in cols if 'positive_example' in c]
        neg_cols = [c for c in cols if 'negative_example' in c]

        def fold_examples(series_list, tag):
            if not series_list:
                return pd.Series([''] * len(df))
            s = pd.Series([''] * len(df))
            for col in series_list:
                si = df[col].where(df[col].notna(), '').astype(str)
                s = (s + ' ' + ((f'[{tag}] ' + si).where(si != '', ''))).str.strip()
            return s

        good = fold_examples(pos_cols, 'GOOD')
        bad = fold_examples(neg_cols, 'BAD')
        texts = (base + ' ' + good + ' ' + bad).str.strip()
        return texts.fillna('')
    
    def _augment_data(self, X_dict, y, df, groups, rules):
        minority_class = 1 if (y == 1).sum() < (y == 0).sum() else 0
        minority_idx = np.where(y == minority_class)[0]
        
        if len(minority_idx) < 10:
            return X_dict, y, groups, rules
        
        n_augment = int(len(minority_idx) * self.spec.augmentation_ratio)
        n_augment = min(n_augment, self.spec.augmentation_max)

        logger.info(f"Augmenting {n_augment} minority samples")
        
        aug_idx = np.random.choice(minority_idx, n_augment, replace=True)
        
        X_aug_dict = {}
        for key, features in X_dict.items():
            if hasattr(features, 'toarray'):
                X_aug_dict[key] = features[aug_idx]
            else:
                augmented = features[aug_idx].copy()
                noise = np.random.normal(0, self.spec.augmentation_noise_std, augmented.shape)
                X_aug_dict[key] = augmented + noise
        
        for key in X_dict.keys():
            if hasattr(X_dict[key], 'toarray'):
                X_dict[key] = vstack([X_dict[key], X_aug_dict[key]])
            else:
                X_dict[key] = np.vstack([X_dict[key], X_aug_dict[key]])
        
        y_aug = y[aug_idx]
        y_combined = np.concatenate([y, y_aug])

        if self.adversarial_weights is not None:
            weights_aug = self.adversarial_weights[aug_idx]
            self.adversarial_weights = np.concatenate([self.adversarial_weights, weights_aug])

        groups_aug = groups[aug_idx] if groups is not None else None
        groups_combined = np.concatenate([groups, groups_aug]) if groups is not None else None
        
        rules_aug = rules[aug_idx] if rules is not None else None
        rules_combined = np.concatenate([rules, rules_aug]) if rules is not None else None
        
        return X_dict, y_combined, groups_combined, rules_combined
    
    def _setup_drift_monitor(self, X_dict, y):
        if not self.spec.track_drift:
            return
        
        self.drift_monitor['prior'] = y.mean()
        self.drift_monitor['feature_means'] = {}
        
        for key, features in X_dict.items():
            if hasattr(features, 'mean'):
                self.drift_monitor['feature_means'][key] = features.mean(axis=0)
    
    def _run_error_analysis(self, X_dict, y, groups):
        logger.info("Error Analysis:")
        
        if self.stacker and self.stacker.oof_predictions is not None:
            oof_ensemble = self.stacker.oof_predictions.mean(axis=1)
            
            auc = roc_auc_score(y, oof_ensemble)
            brier = brier_score_loss(y, oof_ensemble)
            
            logger.info(f"  Overall: AUC={auc:.4f}, Brier={brier:.4f}")
            
            if groups is not None:
                for rule in np.unique(groups)[:5]:
                    mask = groups == rule
                    if mask.sum() > 10:
                        rule_auc = roc_auc_score(y[mask], oof_ensemble[mask])
                        logger.info(f"  Rule '{rule}': AUC={rule_auc:.4f}")
    
    def _save_model_bundle(self):
        model_dir = Path(self.spec.model_path)
        model_dir.mkdir(exist_ok=True)
        
        with open(model_dir / "config.json", "w") as f:
            json.dump(asdict(self.spec), f, indent=2)
        try:
            import joblib
        except ImportError as exc:
            warnings.warn(f"Joblib not available, skipping bundle persistence: {exc}")
            return

        joblib.dump({
            "feature_engineer": self.feature_engineer,
            "stacker": self.stacker,
            "hierarchical": self.hierarchical,
            "gate": self.gate,
            "transformer_model_name": self.spec.transformer_model if self.transformer else None,
            "drift_monitor": self.drift_monitor,
        }, model_dir / "bundle.joblib")
        logger.info(f"Models saved to {model_dir} (config.json, bundle.joblib)")
        if self.transformer and getattr(self.transformer, "model", None):
            tdir = model_dir / "transformer"
            tdir.mkdir(exist_ok=True)
            try:
                self.transformer.model.save_pretrained(str(tdir))
                if self.transformer.tokenizer:
                    self.transformer.tokenizer.save_pretrained(str(tdir))
                logger.info(f"Transformer saved to {tdir}")
            except Exception as exc:
                logger.warning(f"Failed to save transformer: {exc}")
        logger.warning("SECURITY: joblib uses pickle. Only load bundle.joblib from trusted sources.")

def main():
    # set seeds at runtime (avoids side effects on import)
    set_all_seeds(42)
    spec = TrainSpec()

    logger.info("Loading data…")
    train_df = pd.read_csv(spec.train_path)
    test_df = pd.read_csv(spec.test_path)

    logger.info(f"Train: {train_df.shape}  Test: {test_df.shape}")

    pipeline = ProductionPipeline(spec)
    pipeline.fit(train_df, test_df)

    logger.info("Making predictions…")
    predictions = pipeline.predict(test_df)

    logger.info("Building submission…")

    pred = np.asarray(predictions, dtype=float)
    pred = np.clip(pred, 0.0, 1.0)

    sample_path = Path(spec.test_path).with_name("sample_submission.csv")
    sample = pd.read_csv(sample_path)

    if 'row_id' not in test_df.columns:
        raise ValueError("Expected 'row_id' in test.csv; cannot build a valid submission.")

    by_row = pd.Series(pred, index=test_df['row_id']).rename('rule_violation')

    submission = sample[['row_id']].merge(by_row.reset_index(), on='row_id', how='left')
    submission['rule_violation'] = (
        submission['rule_violation'].astype(float).clip(0, 1).fillna(0.5)
    )

    assert submission.shape == sample.shape, "Submission shape must match sample_submission.csv"
    assert submission['rule_violation'].notna().all(), "No NaNs allowed in rule_violation"

    submission.to_csv("/kaggle/working/submission.csv", index=False)
    logger.info("Pipeline complete!")

if __name__ == "__main__":
    main()
